{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d00967-b971-4a85-82e7-029490da6be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-23 23:53:47.279903: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-23 23:53:47.466716: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-23 23:53:47.466791: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-23 23:53:47.500401: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-23 23:53:47.576919: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-23 23:53:47.578337: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-23 23:53:48.496706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b909c46-bd2f-4dcf-874c-b0f3d1f508d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "# Save the model at the end?\n",
    "save_model = True\n",
    "\n",
    "# Batch sizes for training and testing\n",
    "batch_size = 64\n",
    "test_batch_size = 14\n",
    "\n",
    "# Training epochs (usually 10 is a good value)\n",
    "n_epochs = 2\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1.0\n",
    "\n",
    "# Decay rate for adjusting the learning rate\n",
    "gamma = 0.7\n",
    "\n",
    "# Number of target classes in the MNIST data\n",
    "num_classes = 10\n",
    "\n",
    "# Data input shape\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c38ee6-cfdc-4a73-8efc-68ccbc7ec8a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/x_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the MNIST dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/x_train.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/y_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/x_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Work/HSE-MLHS/MLOps/hw/MOBC-mlops/venv/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/x_train.npy'"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "x_train = np.load(\"data/x_train.npy\")\n",
    "y_train = np.load(\"data/y_train.npy\")\n",
    "x_test = np.load(\"data/x_test.npy\")\n",
    "y_test = np.load(\"data/y_test.npy\")\n",
    "\n",
    "# The scaled mean and standard deviation of the MNIST dataset (precalculated)\n",
    "data_mean = 0.1307\n",
    "data_std = 0.3081\n",
    "\n",
    "# Reshape the input data\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = (x_train / 255.0 - data_mean) / data_std\n",
    "x_test = (x_test / 255.0 - data_mean) / data_std\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "y_train = tf.one_hot(y_train.astype(np.int32), depth=num_classes)\n",
    "y_test = tf.one_hot(y_test.astype(np.int32), depth=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11329600-3dfa-4ba1-9900-6c1c897d02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the neural network\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32,\n",
    "            (3, 3),\n",
    "            strides=(1, 1),\n",
    "            padding=\"valid\",\n",
    "            activation=\"relu\",\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        tf.keras.layers.Conv2D(\n",
    "            64, (3, 3), strides=(1, 1), padding=\"valid\", activation=\"relu\"\n",
    "        ),\n",
    "        tf.keras.layers.MaxPool2D(),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d685b976-2704-47f0-a61a-d3f0493dd690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1199882 (4.58 MB)\n",
      "Trainable params: 1199882 (4.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decay the learning rate at a base rate of gamma roughly every epoch, which\n",
    "# is len(x_train) steps\n",
    "scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    learning_rate, decay_steps=len(x_train), decay_rate=gamma\n",
    ")\n",
    "\n",
    "# Define the optimizer to user for gradient descent\n",
    "optimizer = tf.keras.optimizers.Adadelta(scheduler)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "# Display a model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e58c9f4-4c8a-41e0-be7a-80568aee3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 49s 51ms/step - loss: 0.1825 - acc: 0.9445 - val_loss: 0.0457 - val_acc: 0.9856\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 49s 52ms/step - loss: 0.0726 - acc: 0.9785 - val_loss: 0.0343 - val_acc: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f66ff075b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(x_test, y_test),\n",
    "    validation_batch_size=test_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c54888-a23f-42fc-ad77-acb1fb7f5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model:\n",
    "    model.save_weights(\"data/mnist_cnn_tf.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f417337-8bf7-4d69-9602-73df9c040bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
