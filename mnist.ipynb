{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d00967-b971-4a85-82e7-029490da6be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 23:36:45.543519: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-04 23:36:45.568762: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 23:36:45.568785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 23:36:45.569430: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 23:36:45.573541: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-04 23:36:45.573967: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 23:36:46.118094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b909c46-bd2f-4dcf-874c-b0f3d1f508d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "# Save the model at the end?\n",
    "save_model = True\n",
    "\n",
    "# Batch sizes for training and testing\n",
    "batch_size = 64\n",
    "test_batch_size = 14\n",
    "\n",
    "# Training epochs (usually 10 is a good value)\n",
    "n_epochs = 2\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 1.0\n",
    "\n",
    "# Decay rate for adjusting the learning rate\n",
    "gamma = 0.7\n",
    "\n",
    "# Number of target classes in the MNIST data\n",
    "num_classes = 10\n",
    "\n",
    "# Data input shape\n",
    "input_shape = (28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c38ee6-cfdc-4a73-8efc-68ccbc7ec8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "x_train = np.load(\"data/x_train.npy\")\n",
    "y_train = np.load(\"data/y_train.npy\")\n",
    "x_test = np.load(\"data/x_test.npy\")\n",
    "y_test = np.load(\"data/y_test.npy\")\n",
    "\n",
    "# The scaled mean and standard deviation of the MNIST dataset (precalculated)\n",
    "data_mean = 0.1307\n",
    "data_std = 0.3081\n",
    "\n",
    "# Reshape the input data\n",
    "x_train = x_train.reshape(x_train.shape[0], \n",
    "                          x_train.shape[1], \n",
    "                          x_train.shape[2], 1)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], \n",
    "                        x_test.shape[1], \n",
    "                        x_test.shape[2], 1)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = (x_train/255.0 - data_mean) / data_std\n",
    "x_test = (x_test/255.0 - data_mean) / data_std\n",
    "\n",
    "# Convert labels to one-hot vectors\n",
    "y_train = tf.one_hot(y_train.astype(np.int32), depth=num_classes)\n",
    "y_test = tf.one_hot(y_test.astype(np.int32), depth=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11329600-3dfa-4ba1-9900-6c1c897d02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the architecture of the neural network\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), strides=(1,1),\n",
    "                                      padding='valid', \n",
    "                                      activation='relu',\n",
    "                                      input_shape=input_shape),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), strides=(1,1),\n",
    "                                      padding='valid',\n",
    "                                      activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d685b976-2704-47f0-a61a-d3f0493dd690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1199882 (4.58 MB)\n",
      "Trainable params: 1199882 (4.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decay the learning rate at a base rate of gamma roughly every epoch, which\n",
    "# is len(x_train) steps\n",
    "scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    learning_rate,\n",
    "    decay_steps=len(x_train),\n",
    "    decay_rate=gamma)\n",
    "\n",
    "# Define the optimizer to user for gradient descent\n",
    "optimizer = tf.keras.optimizers.Adadelta(scheduler)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Display a model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e58c9f4-4c8a-41e0-be7a-80568aee3a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 48s 50ms/step - loss: 0.1908 - acc: 0.9425 - val_loss: 0.0533 - val_acc: 0.9829\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 48s 51ms/step - loss: 0.0735 - acc: 0.9784 - val_loss: 0.0363 - val_acc: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe13d377910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          validation_batch_size=test_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93c54888-a23f-42fc-ad77-acb1fb7f5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model:\n",
    "    model.save_weights(\"data/mnist_cnn_tf.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f417337-8bf7-4d69-9602-73df9c040bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
